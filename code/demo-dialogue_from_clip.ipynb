{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdavs/surgery/firdavs_work/SurgicalFeedbackAI/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from transformers import AutoProcessor, WhisperForConditionalGeneration\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import os\n",
    "import torch\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"<YOUR_OPENAI_API_KEY>\"\n",
    "huggingface_token = \"<YOUR_HUGGINGFACE_TOKEN>\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueExtractor:\n",
    "    def __init__(self, audio_clip_path, transcription_type='api'):\n",
    "        self.audio_path = audio_clip_path\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.speaker_diarization_model = Pipeline.from_pretrained(\n",
    "            \"pyannote/speaker-diarization-3.1\",\n",
    "            use_auth_token=huggingface_token\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if transcription_type == 'api':\n",
    "            self.processor = None\n",
    "            self.local_transcriber = None\n",
    "        elif transcription_type == 'local':\n",
    "            self.processor = AutoProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "            self.local_transcriber = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\").to(self.device)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid transcription type. Choose either 'api' or 'local'\")\n",
    "        \n",
    "        self.waveform, self.sample_rate = torchaudio.load(self.audio_path)\n",
    "    \n",
    "    def _diarize(self):\n",
    "        output = self.speaker_diarization_model({'waveform': self.waveform, 'sample_rate': self.sample_rate}, \n",
    "                                                min_speakers=2)\n",
    "        segments = list(output.itersegments())\n",
    "        \n",
    "        diarization = pd.DataFrame(columns=['start', 'end', 'speaker'])\n",
    "        for segment in segments:\n",
    "            speakers = output.get_labels(segment)\n",
    "            for speaker in speakers:\n",
    "                start = segment.start\n",
    "                end = segment.end\n",
    "                \n",
    "                diarization.loc[len(diarization)] = [start, end, speaker]\n",
    "\n",
    "        return diarization\n",
    "\n",
    "    def _transcribe_api(self, clip_path):\n",
    "        with open(clip_path, \"rb\") as audio_file:\n",
    "            transcription = openai.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                language=\"en\"\n",
    "            )\n",
    "\n",
    "        return transcription.text\n",
    "\n",
    "    def _transcribe_local(self, audio_path):\n",
    "        wav, sr = torchaudio.load(audio_path)\n",
    "        wav = wav.mean(dim=0).numpy()\n",
    "        inputs = self.processor(wav, return_tensors=\"pt\", sampling_rate=self.sample_rate).to(self.device)\n",
    "        input_features = inputs.input_features\n",
    "        seq = self.local_transcriber.generate(inputs=input_features)\n",
    "\n",
    "        transcription = self.processor.batch_decode(seq, skip_special_tokens=True)[0]\n",
    "\n",
    "        return transcription\n",
    "    \n",
    "    def _transcribe(self, audio_path):\n",
    "        if self.local_transcriber is not None:\n",
    "            return self._transcribe_local(audio_path)\n",
    "        else:\n",
    "            return self._transcribe_api(audio_path)\n",
    "\n",
    "    def extract_dialogue(self):\n",
    "        diarization_df = self._diarize()\n",
    "        \n",
    "        transcription_df = diarization_df.copy()\n",
    "        transcription_df['transcription'] = None\n",
    "        for i in range(len(diarization_df)):\n",
    "            start = diarization_df.loc[i, 'start']\n",
    "            end = diarization_df.loc[i, 'end']\n",
    "            \n",
    "            wav = self.waveform[:, int(start*self.sample_rate) : int(end*self.sample_rate)].clone()\n",
    "            \n",
    "            tmp_path = f\"tmp/temp_{i}.wav\"\n",
    "            os.makedirs(os.path.dirname(tmp_path), exist_ok=True)\n",
    "            torchaudio.save(tmp_path, wav, self.sample_rate)\n",
    "            transcription = self._transcribe(tmp_path)\n",
    "            # os.remove(tmp_path)\n",
    "\n",
    "            transcription_df.loc[i, 'transcription'] = transcription\n",
    "        \n",
    "        return transcription_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030969</td>\n",
       "      <td>3.692844</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>get in touch with them and ask them how they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.152844</td>\n",
       "      <td>5.684094</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Yeah, it would be great. They might get a rude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.114719</td>\n",
       "      <td>4.435344</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>great thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.797844</td>\n",
       "      <td>9.970344</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>They might have to prepare themselves or I'm s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start       end     speaker  \\\n",
       "0  0.030969  3.692844  SPEAKER_00   \n",
       "1  3.152844  5.684094  SPEAKER_01   \n",
       "2  4.114719  4.435344  SPEAKER_00   \n",
       "3  6.797844  9.970344  SPEAKER_01   \n",
       "\n",
       "                                       transcription  \n",
       "0  get in touch with them and ask them how they d...  \n",
       "1  Yeah, it would be great. They might get a rude...  \n",
       "2                                       great thing.  \n",
       "3  They might have to prepare themselves or I'm s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_clip_path = '../sample_audio_clips/clip1.wav'\n",
    "extractor = DialogueExtractor(audio_clip_path, transcription_type='api')\n",
    "extractor.extract_dialogue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "      <th>transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115344</td>\n",
       "      <td>1.414719</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>We don't like to jinx it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.870344</td>\n",
       "      <td>3.473469</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>What, the interview?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.832219</td>\n",
       "      <td>4.148469</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Years ago? No, but well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.025969</td>\n",
       "      <td>6.814719</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>Oh, that's what he said. I hadn't thought of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.021594</td>\n",
       "      <td>6.477219</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>Hey, got it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.995969</td>\n",
       "      <td>9.970344</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>No, years ago, when couples were</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start       end     speaker  \\\n",
       "0  0.115344  1.414719  SPEAKER_00   \n",
       "1  1.870344  3.473469  SPEAKER_01   \n",
       "2  2.832219  4.148469  SPEAKER_00   \n",
       "3  5.025969  6.814719  SPEAKER_01   \n",
       "4  6.021594  6.477219  SPEAKER_00   \n",
       "5  7.995969  9.970344  SPEAKER_00   \n",
       "\n",
       "                                       transcription  \n",
       "0                          We don't like to jinx it.  \n",
       "1                              What, the interview?   \n",
       "2                         Years ago? No, but well...  \n",
       "3  Oh, that's what he said. I hadn't thought of t...  \n",
       "4                                       Hey, got it.  \n",
       "5                   No, years ago, when couples were  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_clip_path = '../sample_audio_clips/clip2.wav'\n",
    "extractor = DialogueExtractor(audio_clip_path, transcription_type='api')\n",
    "extractor.extract_dialogue()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
