{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdavs/surgery/firdavs_work/.venv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio import Inference\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torchaudio.transforms as T\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
    "from utils import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GPT-4o on Fixed-Window Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_fragments_pred_paths = {\n",
    "    case_id: f'results/rolling_fragments/predictions/LFB{case_id}/LFB{case_id} model=TextModel vad_threshold=0.3 fe-threshold=0.csv' for case_id in [1, 2, 9, 10, 18]\n",
    "}\n",
    "rolling_fragments_dfs = {\n",
    "    case_id: pd.read_csv(path, index_col='fragment_id') for case_id, path in rolling_fragments_pred_paths.items()\n",
    "}\n",
    "openai_key_path = 'openai_api_key.txt'\n",
    "\n",
    "def get_prompts(case_id, fragment_id):\n",
    "    transcription = rolling_fragments_dfs[case_id].loc[fragment_id, 'transcription']\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "You are a binary classifier that determines whether a given phrase contains delivery of feedback from a trainer to a trainee where the trainee is conducting urology surgery using the da Vinci robot. The dialogue is between two speakers, a trainer and a trainee. There can be 6 types of feedback:\n",
    "                 \n",
    "1. Anatomic: familiarity with anatomic structures and landmarks. i.e. 'Stay in the correct plane, between the 2 fascial layers.'\n",
    "2. Procedura: pertains to timing and sequence of surgical steps. i.e. 'You can switch to the left side now.'\n",
    "3. Technical: performnace of a discrete task with appropriate knowledge of factors including exposure, instruments, and traction. i.e. 'Buzz it.'\n",
    "4. Praise: a positive remark. i.e. 'Good job.'\n",
    "5. Criticism: a negative remark. i.e. 'It should never be like this.'\n",
    "\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "Classify whether the following phrase contains the delivery of feedback considering.\n",
    "\n",
    "Format your response as follows. DO NOT DO ANY OTHER FORMATTING.:\n",
    "{{'feedback': 'yes'}} if the dialogue contains feedback\n",
    "{{'feedback': 'no'}} if the dialogue does not contain feedback\n",
    "\n",
    "Phrase:\n",
    "{transcription}\n",
    "\n",
    "For example:\n",
    "{{'feedback': 'yes'}}\n",
    "\"\"\"\n",
    "    return {\n",
    "        'system': system_prompt,\n",
    "        'user': user_prompt\n",
    "    }\n",
    "    \n",
    "def detect_feetback(case_id, fragment_id, verbose=False):\n",
    "    prompts = get_prompts(case_id, fragment_id)\n",
    "    set_openai_key(openai_key_path)\n",
    "    client = OpenAI()\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompts['system']},\n",
    "            {\"role\": \"user\", \"content\": prompts['user']}\n",
    "        ],\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    content = completion.choices[0].message.content\n",
    "\n",
    "    print(content) if verbose else None\n",
    "    \n",
    "    try:\n",
    "        classification = ast.literal_eval(content)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(content)\n",
    "        \n",
    "        if 'yes' in content:\n",
    "            classification = {'feedback': 'yes'}\n",
    "        else:\n",
    "            classification = {'feedback': 'no'}\n",
    "    \n",
    "    print(classification) if verbose else None\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Case 1: 100%|██████████| 2009/2009 [19:03<00:00,  1.76it/s]\n",
      "Case 2: 100%|██████████| 919/919 [09:06<00:00,  1.68it/s]\n",
      "Case 9: 100%|██████████| 1582/1582 [15:51<00:00,  1.66it/s]\n",
      "Case 10: 100%|██████████| 1462/1462 [14:48<00:00,  1.65it/s]\n",
      "Case 18: 100%|██████████| 1464/1464 [14:22<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# for each df add a new layer called gpt-4o_pred and have it be the classification from detect_feedback\n",
    "for case_id, df in rolling_fragments_dfs.items():\n",
    "    df['gpt-4o_pred'] = [detect_feetback(case_id, fragment_id) for fragment_id in tqdm(df.index, desc=f'Case {case_id}') if df.loc[fragment_id, 'transcription'] is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(rolling_fragments_dfs, open('results/rolling_fragments/predictions/rolling_fragments_dfs_with_gpt-4o_pred.pkl', 'wb'))\n",
    "rolling_fragments_dfs = pickle.load(open('results/rolling_fragments/predictions/rolling_fragments_dfs_with_gpt-4o_pred.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_paths = {\n",
    "    case_id: f'results/rolling_fragments/true_labels/LFB{case_id} model=TextModel vad_threshold=0.3 fe-threshold=0.csv' for case_id in [1, 2, 9, 10, 18]\n",
    "}\n",
    "true_labels_dfs = {\n",
    "    case_id: pd.read_csv(path) for case_id, path in true_labels_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o Metrics\n",
      "{\n",
      "    \"precision\": [\n",
      "        0.5971557453987111,\n",
      "        0.1621322716641781\n",
      "    ],\n",
      "    \"recall\": [\n",
      "        0.6177625257897931,\n",
      "        0.059592782229525874\n",
      "    ],\n",
      "    \"f1\": [\n",
      "        0.6021951935632186,\n",
      "        0.1102710011858039\n",
      "    ],\n",
      "    \"roc_auc\": [\n",
      "        0.6865911150959215,\n",
      "        0.029165390909575643\n",
      "    ],\n",
      "    \"accuracy\": [\n",
      "        0.7176570425240889,\n",
      "        0.04314773925405801\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(case_id: int, true_labels_dfs: dict[int, pd.DataFrame], rolling_fragments_dfs: dict[int, pd.DataFrame]) -> dict:\n",
    "    rolling_fragment_df = rolling_fragments_dfs[case_id].reset_index().dropna()\n",
    "    rolling_fragment_df['secs'] = rolling_fragment_df['start_time'].apply(lambda x: int(x.split(':')[-1]) + 60*int(x.split(':')[-2]) + 60*60*int(x.split(':')[-3]))\n",
    "    true_labels_df = true_labels_dfs[case_id].reset_index().dropna()\n",
    "    \n",
    "    df = pd.merge(true_labels_df, rolling_fragment_df, on='secs')\n",
    "    df['gpt-4o_pred'] = df['gpt-4o_pred'].apply(lambda x: 1. if 'yes' in x['feedback'] else 0.)\n",
    "    y_true = df['fb_instance'].values\n",
    "    y_pred_gpt_4o = df['gpt-4o_pred'].values\n",
    "    y_pred_bert = df['pred'].values\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_gpt_4o, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_gpt_4o)\n",
    "    accuracy = accuracy_score(y_true, y_pred_gpt_4o)\n",
    "    gpt4o_metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_bert, average='binary')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_bert)\n",
    "    accuracy = accuracy_score(y_true, y_pred_bert)\n",
    "    bert_metrics = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    return {\n",
    "        'gpt-4o': gpt4o_metrics,\n",
    "        'bert': bert_metrics\n",
    "    }\n",
    "\n",
    "metrics = {case_id: get_metrics(case_id, true_labels_dfs, rolling_fragments_dfs) for case_id in [1, 2, 9, 10, 18]}\n",
    "\n",
    "# Average metrics\n",
    "gpt4o_metrics = {k: (np.mean([v['gpt-4o'][k] for v in metrics.values()]), np.std([v['gpt-4o'][k] for v in metrics.values()])) for k in metrics[1]['gpt-4o'].keys()}\n",
    "print('GPT-4o Metrics')\n",
    "print(json.dumps(gpt4o_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BERT on Dialogue Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firdavs/surgery/firdavs_work/.venv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import set_seed, TrainingArguments, Trainer, BertForSequenceClassification\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from models import TextModel\n",
    "from models.dataset import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "set_seed(random_state)\n",
    "auxes = {\n",
    "    'dialogue': 'dialogue',\n",
    "    'hallucination removal': 'reduced hallucinations',\n",
    "    'trainee/trainer id': 'all phrases'\n",
    "}\n",
    "paths = {}\n",
    "case_ids = [1, 2, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 33]\n",
    "test_case_ids = [1, 2, 9, 10, 18]\n",
    "for case_id in case_ids:\n",
    "    paths[case_id] = {}\n",
    "    for k, aux in auxes.items():\n",
    "        paths[case_id][k] = f\"./results/extract_dialogue/aligned_fb_detection/LFB{case_id}_full '{aux}'.csv\"\n",
    "\n",
    "dfs = {case_id: {k: pd.read_csv(v) for k, v in paths[case_id].items()} for case_id in case_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_context_dialogue(context_dialogue):\n",
    "    parsed = ' '.join([x[x.index('[')+1:x.index(']')].replace(\"'\", '') for x in context_dialogue.split('\\n')[1:-1]])\n",
    "    # parsed = context_dialogue\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    if isinstance(eval_pred, dict):\n",
    "        labels = eval_pred['label_ids']\n",
    "        preds = eval_pred['predictions'].argmax(-1)\n",
    "    else:\n",
    "        labels = eval_pred.label_ids\n",
    "        preds = eval_pred.predictions.argmax(-1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    roc_auc = roc_auc_score(labels, preds)\n",
    "    \n",
    "    metrics =  {'accuracy': accuracy,\n",
    "                'roc_auc': roc_auc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1}\n",
    "    return metrics\n",
    "\n",
    "def train(\n",
    "    output_dir: str,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    warmup_steps: int,\n",
    "    weight_decay: float,\n",
    "    eval_save_strategy: str,\n",
    "    save_steps: int,\n",
    "    eval_steps: int,\n",
    "    metric_for_best_model: str,\n",
    "    report_to: str,\n",
    "    seed: int,\n",
    "    lr_scheduler_type: str,\n",
    "    lr_scheduler_kwargs: dict,\n",
    "    model: nn.Module,\n",
    "    train_dataset: torch.utils.data.Dataset,\n",
    "    eval_dataset: torch.utils.data.Dataset,\n",
    "):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        eval_strategy=eval_save_strategy,\n",
    "        save_strategy=eval_save_strategy,\n",
    "        save_steps=save_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=metric_for_best_model,\n",
    "        report_to=report_to,\n",
    "        seed=seed,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "        save_total_limit=5,\n",
    "        remove_unused_columns=False\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    return trainer.model\n",
    "\n",
    "def evaluate(model: TextModel, test_dataset: TextDataset, batch_size: int):\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        for k, v in batch.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                batch[k] = v.to(model.device)\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        token_type_ids = batch['token_type_ids']\n",
    "        labels = torch.tensor([1*x for x in batch['label']]).to(model.device)\n",
    "        outputs = model.forward(input_ids, attention_mask, token_type_ids, labels=labels)\n",
    "        all_preds.extend(outputs.logits.cpu().detach().numpy())\n",
    "        all_labels.extend(labels.cpu().detach().numpy())\n",
    "    metrics = compute_metrics({'label_ids': all_labels, 'predictions': np.array(all_preds)})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aligned_fb_detection_df = pd.concat((dfs[case_id]['dialogue'] for case_id in case_ids if case_id not in test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "all_aligned_fb_detection_df = all_aligned_fb_detection_df[['full_clip_path', 'context_dialogue', 'true_fb_instance']]\n",
    "\n",
    "train_df = all_aligned_fb_detection_df.iloc[:int(0.8*len(all_aligned_fb_detection_df))].reset_index(drop=True)\n",
    "val_df = all_aligned_fb_detection_df.iloc[int(0.8*len(all_aligned_fb_detection_df)):].reset_index(drop=True)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    transcriptions_df=train_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")\n",
    "val_dataset = TextDataset(\n",
    "    transcriptions_df=val_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Text Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No class weighting!\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'text_model': 'bert-base-uncased',\n",
    "    # 'text_model': 'results/extract_dialogue/bert/checkpoint-4500',\n",
    "    # 'config': 'bert-base-uncased',\n",
    "    'class_weights': None,\n",
    "    'num_classes': 2\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TextModel(params_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3537' max='3537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3537/3537 03:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.510100</td>\n",
       "      <td>0.556685</td>\n",
       "      <td>0.722953</td>\n",
       "      <td>0.712605</td>\n",
       "      <td>0.425904</td>\n",
       "      <td>0.693916</td>\n",
       "      <td>0.527838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.450168</td>\n",
       "      <td>0.818413</td>\n",
       "      <td>0.709008</td>\n",
       "      <td>0.611364</td>\n",
       "      <td>0.511407</td>\n",
       "      <td>0.556936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.406383</td>\n",
       "      <td>0.832414</td>\n",
       "      <td>0.726149</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.534221</td>\n",
       "      <td>0.587252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.444320</td>\n",
       "      <td>0.832414</td>\n",
       "      <td>0.665852</td>\n",
       "      <td>0.758893</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.492940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.487823</td>\n",
       "      <td>0.834535</td>\n",
       "      <td>0.724127</td>\n",
       "      <td>0.663462</td>\n",
       "      <td>0.524715</td>\n",
       "      <td>0.585987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.421886</td>\n",
       "      <td>0.845566</td>\n",
       "      <td>0.719032</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>0.490494</td>\n",
       "      <td>0.586364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>0.441688</td>\n",
       "      <td>0.852779</td>\n",
       "      <td>0.735869</td>\n",
       "      <td>0.739946</td>\n",
       "      <td>0.524715</td>\n",
       "      <td>0.614016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(\n",
    "    output_dir='results/extract_dialogue/bert/dialogue',\n",
    "    epochs=3,\n",
    "    batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    report_to='none',\n",
    "    seed=random_state,\n",
    "    lr_scheduler_type='linear',\n",
    "    lr_scheduler_kwargs=None,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aligned_fb_detection = pd.concat((dfs[case_id]['dialogue'] for case_id in case_ids if test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "test_aligned_fb_detection = test_aligned_fb_detection[['full_clip_path', 'context_dialogue', 'true_fb_instance']].reset_index(drop=True)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    transcriptions_df=test_aligned_fb_detection,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:26<00:00, 18.47it/s]\n"
     ]
    }
   ],
   "source": [
    "bert_metrics = evaluate(model, test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8782280621869512,\n",
       " 'roc_auc': 0.7832625105090458,\n",
       " 'precision': 0.8544061302681992,\n",
       " 'recall': 0.5991402471789361,\n",
       " 'f1': 0.704358812381554}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 +Reduced Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aligned_fb_detection_df = pd.concat((dfs[case_id]['hallucination removal'] for case_id in case_ids if case_id not in test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "all_aligned_fb_detection_df = all_aligned_fb_detection_df[['full_clip_path', 'context_dialogue', 'true_fb_instance']]\n",
    "\n",
    "train_df = all_aligned_fb_detection_df.iloc[:int(0.8*len(all_aligned_fb_detection_df))].reset_index(drop=True)\n",
    "val_df = all_aligned_fb_detection_df.iloc[int(0.8*len(all_aligned_fb_detection_df)):].reset_index(drop=True)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    transcriptions_df=train_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")\n",
    "val_dataset = TextDataset(\n",
    "    transcriptions_df=val_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Text Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No class weighting!\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'text_model': 'bert-base-uncased',\n",
    "    # 'text_model': 'results/extract_dialogue/bert/checkpoint-4500',\n",
    "    # 'config': 'bert-base-uncased',\n",
    "    'class_weights': None,\n",
    "    'num_classes': 2\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TextModel(params_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='897' max='897' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [897/897 00:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.567200</td>\n",
       "      <td>0.548560</td>\n",
       "      <td>0.752922</td>\n",
       "      <td>0.737330</td>\n",
       "      <td>0.641593</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.662100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(\n",
    "    output_dir='results/extract_dialogue/bert/hallucination_removal',\n",
    "    epochs=3,\n",
    "    batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    report_to='none',\n",
    "    seed=random_state,\n",
    "    lr_scheduler_type='linear',\n",
    "    lr_scheduler_kwargs=None,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aligned_fb_detection = pd.concat((dfs[case_id]['hallucination removal'] for case_id in case_ids if test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "test_aligned_fb_detection = test_aligned_fb_detection[['full_clip_path', 'context_dialogue', 'true_fb_instance']].reset_index(drop=True)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    transcriptions_df=test_aligned_fb_detection,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:11<00:00, 12.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8059496567505721,\n",
       " 'roc_auc': 0.796465840825861,\n",
       " 'precision': 0.7803602556653109,\n",
       " 'recall': 0.740761169332598,\n",
       " 'f1': 0.7600452744765138}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_metrics = evaluate(model, test_dataset, batch_size=32)\n",
    "bert_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 +Trainee/Trainer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aligned_fb_detection_df = pd.concat((dfs[case_id]['trainee/trainer id'] for case_id in case_ids if case_id not in test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "all_aligned_fb_detection_df = all_aligned_fb_detection_df[['full_clip_path', 'context_dialogue', 'true_fb_instance']]\n",
    "\n",
    "train_df = all_aligned_fb_detection_df.iloc[:int(0.8*len(all_aligned_fb_detection_df))].reset_index(drop=True)\n",
    "val_df = all_aligned_fb_detection_df.iloc[int(0.8*len(all_aligned_fb_detection_df)):].reset_index(drop=True)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    transcriptions_df=train_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")\n",
    "val_dataset = TextDataset(\n",
    "    transcriptions_df=val_df,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Text Model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No class weighting!\n"
     ]
    }
   ],
   "source": [
    "params_model = {\n",
    "    'text_model': 'bert-base-uncased',\n",
    "    # 'text_model': 'results/extract_dialogue/bert/checkpoint-4500',\n",
    "    # 'config': 'bert-base-uncased',\n",
    "    'class_weights': None,\n",
    "    'num_classes': 2\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TextModel(params_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='897' max='897' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [897/897 00:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.462300</td>\n",
       "      <td>0.337381</td>\n",
       "      <td>0.841402</td>\n",
       "      <td>0.823325</td>\n",
       "      <td>0.679144</td>\n",
       "      <td>0.783951</td>\n",
       "      <td>0.727794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = train(\n",
    "    output_dir='results/extract_dialogue/bert/trainee-trainer-id',\n",
    "    epochs=3,\n",
    "    batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    report_to='none',\n",
    "    seed=random_state,\n",
    "    lr_scheduler_type='linear',\n",
    "    lr_scheduler_kwargs=None,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aligned_fb_detection = pd.concat((dfs[case_id]['hallucination removal'] for case_id in case_ids if test_case_ids)).sample(frac=1, random_state=random_state)\n",
    "test_aligned_fb_detection = test_aligned_fb_detection[['full_clip_path', 'context_dialogue', 'true_fb_instance']].reset_index(drop=True)\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    transcriptions_df=test_aligned_fb_detection,\n",
    "    tokenizer=tokenizer,\n",
    "    text_col='context_dialogue',\n",
    "    label_col='true_fb_instance',\n",
    "    file_col='full_clip_path'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:11<00:00, 12.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7453089244851259,\n",
       " 'roc_auc': 0.714074210051639,\n",
       " 'precision': 0.7859477124183006,\n",
       " 'recall': 0.5306122448979592,\n",
       " 'f1': 0.633519920974646}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_metrics = evaluate(model, test_dataset, batch_size=32)\n",
    "bert_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Other Hallucination Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import torch\n",
    "from models import ExtractDialogueModel\n",
    "from utils import whisper_transcribe\n",
    "from utils import set_openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 698/698 [14:24<00:00,  1.24s/it]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1466/1466 [30:51<00:00,  1.26s/it] \n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [20:18<00:00,  1.16s/it]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1038/1038 [21:04<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "openai_key_path = 'openai_api_key.txt'\n",
    "\n",
    "# Run second transcriptions\n",
    "for case_id in [2, 9, 10, 18]:\n",
    "    device = torch.device(\"cuda\")\n",
    "    params_extract_dialogue = {\n",
    "        'speaker_diarization_model': 'pyannote/speaker-diarization-3.1',\n",
    "        'speaker_embedding_model': 'pyannote/embedding',\n",
    "        'hf_token_path': 'huggingface_token.txt',\n",
    "        'openai_key_path': openai_key_path, \n",
    "        'transcribe_fn': whisper_transcribe,\n",
    "        'full_audio_path': f'../../full_audios/LFB{case_id}_full.wav',\n",
    "        'interval': 180,\n",
    "        'console_times_path': '../../annotations/console_times/combined_console_times_secs.csv',\n",
    "        'fb_annot_path': '../../clips_no_wiggle/fbk_cuts_no_wiggle_0_4210.csv',\n",
    "        'vad_activity_path': f'../../full_VADs/LFB{case_id}_full_activity.csv',\n",
    "        'diarizations_save_path': f'results/extract_dialogue/diarizations/LFB{case_id}_full.csv',\n",
    "        'transcriptions_save_path': f'results/extract_dialogue/transcriptions/LFB{case_id}_full_2.csv',\n",
    "        'identifications_save_path': f'results/extract_dialogue/dfifications/LFB{case_id}_full_2.csv',\n",
    "        'fb_detection_save_path': f\"results/extract_dialogue/fb_detection/LFB{case_id}_full_2 'dialogue' thresh={0.8}.csv\",\n",
    "        'audio_clips_dir': 'results/extract_dialogue/audio_clips',\n",
    "        'trainer_anchors_dir': 'results/extract_dialogue/anchors/trainer',\n",
    "        'trainee_anchors_dir': 'results/extract_dialogue/anchors/trainee',\n",
    "        'tmp_dir': 'tmp',\n",
    "        'seed': 42,\n",
    "        'min_n_speakers': 2,\n",
    "        'max_n_speakers': 2,\n",
    "        'embedding_dist_thresh': 0.8\n",
    "    }\n",
    "    set_openai_key(openai_key_path)\n",
    "    model = ExtractDialogueModel(params_extract_dialogue, device)\n",
    "\n",
    "    model.full_diarization(load_saved=True)\n",
    "    model.full_transcription(load_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hallucinations(df1, df2, verbose=False):\n",
    "    df1.replace(np.nan, '', inplace=True)\n",
    "    df2.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "    hallucinations = np.zeros(len(df1), dtype=bool)\n",
    "    for i in range(len(df1)):\n",
    "        if df1.iloc[i].transcription != df2.iloc[i].transcription:\n",
    "            hallucinations[i] = True\n",
    "            if verbose:\n",
    "                print(f\"df 1: {df1.iloc[i].transcription}\")\n",
    "                print(f\"df 2: {df2.iloc[i].transcription}\")\n",
    "        if df1.iloc[i].transcription == '' and df2.iloc[i].transcription == '':\n",
    "            hallucinations[i] = True\n",
    "            if verbose:\n",
    "                print(f\"df 1: {df1.iloc[i].transcription}\")\n",
    "                print(f\"df 2: {df2.iloc[i].transcription}\")\n",
    "    return hallucinations\n",
    "\n",
    "transcriptions_df1 = {case_id: pd.read_csv(f'results/extract_dialogue/transcriptions/LFB{case_id}_full.csv') for case_id in [1, 2, 9, 10, 18]}\n",
    "transcriptions_df2 = {case_id: pd.read_csv(f'results/extract_dialogue/transcriptions/LFB{case_id}_full_2.csv') for case_id in [1, 2, 9, 10, 18]}\n",
    "hallucinations = {case_id: get_hallucinations(transcriptions_df1[case_id], transcriptions_df2[case_id]) for case_id in [1, 2, 9, 10, 18]}\n",
    "final_transcriptions_df = {case_id: transcriptions_df1[case_id].copy().iloc[~hallucinations[case_id]] for case_id in [1, 2, 9, 10, 18]}\n",
    "\n",
    "for case_id in [1, 2, 9, 10, 18]:\n",
    "    final_transcriptions_df[case_id].to_csv(f'results/extract_dialogue/transcriptions/LFB{case_id}_full_-reduced_hallucinations_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1507/1507 [00:04<00:00, 372.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of contexts: 1502\n",
      "aux: dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1497/1497 [15:50<00:00,  1.57it/s]\n",
      "100%|██████████| 1497/1497 [03:00<00:00,  8.31it/s] \n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 622/622 [00:01<00:00, 412.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of contexts: 617\n",
      "aux: dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 612/612 [06:40<00:00,  1.53it/s]\n",
      "100%|██████████| 612/612 [01:09<00:00,  8.80it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1269/1269 [00:03<00:00, 395.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of contexts: 1264\n",
      "aux: dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1259/1259 [13:32<00:00,  1.55it/s]\n",
      "100%|██████████| 1259/1259 [01:32<00:00, 13.65it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 968/968 [00:02<00:00, 424.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of contexts: 963\n",
      "aux: dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [10:21<00:00,  1.54it/s]\n",
      "100%|██████████| 958/958 [01:48<00:00,  8.82it/s]\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878/878 [00:02<00:00, 427.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of contexts: 873\n",
      "aux: dialogue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 868/868 [09:24<00:00,  1.54it/s]\n",
      "100%|██████████| 868/868 [01:10<00:00, 12.28it/s]\n"
     ]
    }
   ],
   "source": [
    "openai_key_path = 'openai_api_key.txt'\n",
    "all_metrics = {}\n",
    "# Run second transcriptions\n",
    "for case_id in [1, 2, 9, 10, 18]:\n",
    "    device = torch.device(\"cuda\")\n",
    "    params_extract_dialogue = {\n",
    "        'speaker_diarization_model': 'pyannote/speaker-diarization-3.1',\n",
    "        'speaker_embedding_model': 'pyannote/embedding',\n",
    "        'hf_token_path': 'huggingface_token.txt',\n",
    "        'openai_key_path': openai_key_path, \n",
    "        'transcribe_fn': whisper_transcribe,\n",
    "        'full_audio_path': f'../../full_audios/LFB{case_id}_full.wav',\n",
    "        'interval': 180,\n",
    "        'console_times_path': '../../annotations/console_times/combined_console_times_secs.csv',\n",
    "        'fb_annot_path': '../../clips_no_wiggle/fbk_cuts_no_wiggle_0_4210.csv',\n",
    "        'vad_activity_path': f'../../full_VADs/LFB{case_id}_full_activity.csv',\n",
    "        'diarizations_save_path': f'results/extract_dialogue/diarizations/LFB{case_id}_full.csv',\n",
    "        'transcriptions_save_path': f'results/extract_dialogue/transcriptions/LFB{case_id}_full_-reduced_hallucinations_base.csv',\n",
    "        'identifications_save_path': f'results/extract_dialogue/identifications/LFB{case_id}_full_-reduced_hallucinations_base.csv',\n",
    "        'fb_detection_save_path': f\"results/extract_dialogue/fb_detection/LFB{case_id}_full_-reduced_hallucinations_base 'dialogue' thresh={0.8}.csv\",\n",
    "        'audio_clips_dir': 'results/extract_dialogue/audio_clips',\n",
    "        'trainer_anchors_dir': 'results/extract_dialogue/anchors/trainer',\n",
    "        'trainee_anchors_dir': 'results/extract_dialogue/anchors/trainee',\n",
    "        'tmp_dir': 'tmp',\n",
    "        'seed': 42,\n",
    "        'min_n_speakers': 2,\n",
    "        'max_n_speakers': 2,\n",
    "        'embedding_dist_thresh': 0.8\n",
    "    }\n",
    "    set_openai_key(openai_key_path)\n",
    "    model = ExtractDialogueModel(params_extract_dialogue, device)\n",
    "\n",
    "    model.full_diarization(load_saved=True)\n",
    "    model.full_transcription(load_saved=True)\n",
    "    model.full_identification(load_saved=False)\n",
    "    model.full_fb_detection(load_saved=False, aux='dialogue')\n",
    "    model.full_aligned_fb_detection(load_saved=False)\n",
    "    all_metrics[case_id] = model.evaluate(weighting='binary', model_type='fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/4db4899737a38b2d618bbd74350915aa10293cb2/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.4.0+cu118. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "openai_key_path = 'openai_api_key.txt'\n",
    "all_metrics = {}\n",
    "# Run second transcriptions\n",
    "for case_id in [1, 2, 9, 10, 18]:\n",
    "    device = torch.device(\"cuda\")\n",
    "    params_extract_dialogue = {\n",
    "        'speaker_diarization_model': 'pyannote/speaker-diarization-3.1',\n",
    "        'speaker_embedding_model': 'pyannote/embedding',\n",
    "        'hf_token_path': 'huggingface_token.txt',\n",
    "        'openai_key_path': openai_key_path, \n",
    "        'transcribe_fn': whisper_transcribe,\n",
    "        'full_audio_path': f'../../full_audios/LFB{case_id}_full.wav',\n",
    "        'interval': 180,\n",
    "        'console_times_path': '../../annotations/console_times/combined_console_times_secs.csv',\n",
    "        'fb_annot_path': '../../clips_no_wiggle/fbk_cuts_no_wiggle_0_4210.csv',\n",
    "        'vad_activity_path': f'../../full_VADs/LFB{case_id}_full_activity.csv',\n",
    "        'diarizations_save_path': f'results/extract_dialogue/diarizations/LFB{case_id}_full.csv',\n",
    "        'transcriptions_save_path': f'results/extract_dialogue/transcriptions/LFB{case_id}_full_-reduced_hallucinations_base.csv',\n",
    "        'identifications_save_path': f'results/extract_dialogue/identifications/LFB{case_id}_full_-reduced_hallucinations_base.csv',\n",
    "        'fb_detection_save_path': f\"results/extract_dialogue/fb_detection/LFB{case_id}_full_-reduced_hallucinations_base 'dialogue' thresh={0.8}.csv\",\n",
    "        'audio_clips_dir': 'results/extract_dialogue/audio_clips',\n",
    "        'trainer_anchors_dir': 'results/extract_dialogue/anchors/trainer',\n",
    "        'trainee_anchors_dir': 'results/extract_dialogue/anchors/trainee',\n",
    "        'tmp_dir': 'tmp',\n",
    "        'seed': 42,\n",
    "        'min_n_speakers': 2,\n",
    "        'max_n_speakers': 2,\n",
    "        'embedding_dist_thresh': 0.8\n",
    "    }\n",
    "    set_openai_key(openai_key_path)\n",
    "    model = ExtractDialogueModel(params_extract_dialogue, device)\n",
    "\n",
    "    model.full_diarization(load_saved=True)\n",
    "    model.full_transcription(load_saved=True)\n",
    "    model.full_identification(load_saved=True)\n",
    "    model.full_fb_detection(load_saved=True, aux='dialogue')\n",
    "    model.full_aligned_fb_detection(load_saved=True)\n",
    "    all_metrics[case_id] = model.evaluate(weighting='binary', model_type='fb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "{\n",
      "    \"precision\": [\n",
      "        0.568697884891402,\n",
      "        0.06462143686647753\n",
      "    ],\n",
      "    \"recall\": [\n",
      "        0.6128425566418169,\n",
      "        0.0808942812293493\n",
      "    ],\n",
      "    \"f1\": [\n",
      "        0.5879814215561103,\n",
      "        0.06591532017344578\n",
      "    ],\n",
      "    \"roc_auc\": [\n",
      "        0.68542848891328,\n",
      "        0.04795825307630654\n",
      "    ],\n",
      "    \"accuracy\": [\n",
      "        0.7234343853815178,\n",
      "        0.0724305793607616\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Average metrics\n",
    "avg_metrics = {k: (np.mean([v[k] for v in all_metrics.values()]), np.std([v[k] for v in all_metrics.values()])) for k in all_metrics[1].keys()}\n",
    "print('Metrics')\n",
    "print(json.dumps(avg_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'precision': 0.6550802139037433,\n",
       "  'recall': 0.6805555555555556,\n",
       "  'f1': 0.667574931880109,\n",
       "  'roc_auc': 0.6554640241961159,\n",
       "  'accuracy': 0.6558533145275035},\n",
       " 2: {'precision': 0.6387434554973822,\n",
       "  'recall': 0.648936170212766,\n",
       "  'f1': 0.6437994722955145,\n",
       "  'roc_auc': 0.6902268399701963,\n",
       "  'accuracy': 0.6966292134831461},\n",
       " 9: {'precision': 0.5095541401273885,\n",
       "  'recall': 0.45714285714285713,\n",
       "  'f1': 0.4819277108433735,\n",
       "  'roc_auc': 0.651417119954194,\n",
       "  'accuracy': 0.744807121661721},\n",
       " 10: {'precision': 0.5081967213114754,\n",
       "  'recall': 0.6138613861386139,\n",
       "  'f1': 0.5560538116591929,\n",
       "  'roc_auc': 0.653084539223153,\n",
       "  'accuracy': 0.6655405405405406},\n",
       " 18: {'precision': 0.5319148936170213,\n",
       "  'recall': 0.6637168141592921,\n",
       "  'f1': 0.5905511811023622,\n",
       "  'roc_auc': 0.7769499212227408,\n",
       "  'accuracy': 0.8543417366946778}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
